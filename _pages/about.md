---
permalink: /
title: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

**Meng Zhu** earned the Ph.D. degree in information management and information systems from Nanchang University, China in 2024, apprenticing under Prof. [Weidong Min](https://smcs.ncu.edu.cn/szdw/jsml/ce79f6f094154067a7dda50292b90603.htm). He earned the M.E. and B.E. degrees in computer science and technology from Nanchang University, China in 2021 and 2018, respectively.  His current research interests are basic architectures of AI, learning dynamics of deep neural network models, AI4Science, multimedia forensics and snapshot compressive imaging. He is a Reviewer of *EAAI*.

# Research Interests

1. Basic Architectures of AI.
2. Learning Dynamics of Deep Neural Network Models.
3. AI4Science.
4. Multimedia Forensics.

News
======



# Work Experience



Educational Background
======

|      Date       |              University Attended              |                            Degree                            |
| :-------------: | :-------------------------------------------: | :----------------------------------------------------------: |
| 2021.09-2024.12 | [Nanchang University](https://www.ncu.edu.cn) | Ph.D. Degree in Information Management and Information Systems |
| 2018.09-2021.06 |              Nanchang University              |        M.E. Degree in Computer Science and Technology        |
| 2014.09-2018.06 |              Nanchang University              |        B.E. Degree in Computer Science and Technology        |



# Representative Achievements

### Basic Architectures of AI

1. **Meng Zhu**, Weidong Min*, Junwei Han, Qing Han, Shimiao Cui. Improved channel attention methods via hierarchical pooling and reducing information loss [J]. Pattern Recognition, 2024, 148: 1-9. DOI: 10.1016/j.patcog.2023.110148.
2. **Meng Zhu**, Weidong Min*, Qi Wang, Song Zou, Xinhao Chen. PFLU and FPFLU: Two novel non-monotonic activation functions in convolutional neural networks [J]. Neurocomputing, 2021, 429: 110-117. DOI: 10.1016/j.neucom.2020.11.068.
3. **Meng Zhu**, Weidong Min*, Qing Han, Guowei Zhan, Qiyan Fu, Jiahao Li. ShuffleNeMt: Modern lightweight convolutional neural network architecture [J]. Pattern Analysis and Applications, 2024, 27 (4): 123-134. DOI: 10.1007/s10044-024-01327-3.
4. **Meng Zhu**, Weidong Min*, Hongyue Xiang, Cheng Zha, Zheng Huang, Longfei Li, Qiyan Fu. Spatial decomposition and aggregation for attention in convolutional neural networks [J]. International Journal of Pattern Recognition and Artificial Intelligence, 2024, 38 (1): 1-15. DOI: 10.1142/S0218001423520195.
5. **朱梦**，闵卫东*，张煜，段静雯. 基于HardSoftmax的并行选择核注意力 [J]. 计算机工程与应用，2021，57 (21): 95-101. DOI: 10.3778/j.issn.1002-8331.2010-0085.
6. **Meng Zhu**, Weidong Min*, Jiahao Li, Mengxue Liu, Ziyang Deng, Yao Zhang. Constructing a smoothed Leaky ReLU using a linear combination of the smoothed ReLU and identity function [J]. Neural Computing and Applications, 2025: 1-14. DOI: 10.1007/s00521-024-10935-3.

### Image Inpainting

1. Hongyue Xiang, Weidong Min*, Qing Han, Cheng Zha, Qian Liu, **Meng Zhu**. Structure-aware multi-view image inpainting using dual consistency attention [J]. Information Fusion, 2024, 104: 1-11. DOI: 10.1016/j.inffus.2023.102174.

### Intelligent Transportation

1. Qi Wang, Weidong Min*, Qing Han, Ziyuan Yang, Xin Xiong, **Meng Zhu**, Haoyu Zhao. Viewpoint adaptation learning with cross-view distance metric for robust vehicle re-identification [J]. Information Sciences, 2021, 564: 71-84. DOI: 10.1016/j.ins.2021.02.013.
2. Qiyan Fu, Weidong Min*, Chubbo Li, Haoyu Zhao, Ye Cao, **Meng Zhu**. MSCNet: Dense vehicle counting method based on multi-scale dilated convolution channel-aware deep network [J]. GeoInformatica, 2024, 28 (2): 245-269. DOI: 10.1007/s10707-023-00503-7.

### Ship Detection

1. Cheng Zha, Weidong Min*, Qing Han, Wei Li, Xin Xiong, Qi Wang, **Meng Zhu**. SAR ship localization method with denoising and feature refinement [J]. Engineering Applications of Artificial Intelligence, 2023, 123: 1-13. DOI: 10.1016/j.engappai.2023.106444. 
